# Overview

Uses Apache Spark in an iterative fashion to create the following:

Estimation of PageRank values under ideal conditions: Creates a sorted list (in descending order) of Wikipedia pages based on their ideal PageRank value. Each row of the output contains the title of the article and its PageRank value. This computation is performed in my own Spark cluster with 5 machines with results from 25 iterations.

Estimation of the PageRank values while considering dead-end articles: Creates a sorted list (in descending order) of Wikipedia pages based on their PageRank value with taxation. Each row of the output contains the title of the article and its PageRank value. This computation is performed in my own Spark cluster with 5 machines with results from 25 iterations.

Analysis of the above results: Creating a Wikipedia Bomb: Creates a Wikipedia Bomb that returns the "Rocky Mountain National Park" wikipedia page for the search key word "surfing". To do this, I modify the link data file and show that the "Rocky Mountain National Park" page generates the highest PageRank among all of the pages containing "surfing" as part of their titles.

Input Data: PA3 uses Wikipedia dump generated by Henry Haselgrove. The input dataset contains Wikipedia-Links-Simple-Sorted and Wikipedia-Titles-Sorted. links-simple-sorted.txt, contains one line for each page that has links from it. The format of the lines is as follows:

from1: to11 to12 to13 ... 
from2: to21 to22 to23 ... 
where from1 is an integer labeling a page that has links from it, and to11 to12 to13 ... are integers labeling all the pages that the page links to. To find a page title that corresponds to integer n, just look up the n-th line in the file titles-sorted.txt, a UTF8-encoded text file.
